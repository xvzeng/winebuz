{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d858c894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ded3f71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a7af23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original R4W TABLE\n",
    "def get_volume_r4w(df, start_wk, end_wk):\n",
    "    rolling_window_df = pd.DataFrame([\n",
    "    {\n",
    "        'rolling_order':i,\n",
    "        'rolling_start': end - pd.Timedelta(weeks=4),\n",
    "        'roling_end':end,\n",
    "        'rolling_window_range_start': (end - pd.Timedelta(weeks=4)).strftime('%Y-%m-%d') + ' to ' + end.strftime('%Y-%m-%d'),\n",
    "        'rollingw_window_range_end': end.strftime('%Y-%m-%d') + ' to ' + (end + pd.Timedelta(weeks=4)).strftime('%Y-%m-%d')\n",
    "    }\n",
    "    for i, end in enumerate(pd.date_range(start=start_wk, end = end_wk, freq='W-FRI'))])\n",
    "\n",
    "    #step1 build all accounts x rolling_order combinations\n",
    "    all_accounts = df_all['account_id'].unique()\n",
    "    all_orders = rolling_window_df['rolling_order'].unique()\n",
    "    account_order_grid = pd.MultiIndex.from_product([all_accounts, all_orders], \n",
    "                                                    names=['Account ID', 'rolling_order']).to_frame(index=False)\n",
    "    \n",
    "    #stept2: compute metrics only where data exists\n",
    "    volume_records = []\n",
    "    for acct in df_all['account_id'].unique():\n",
    "        df_acct = df_all[df_all['account_id'] == acct]\n",
    "        for _, window in rolling_window_df.iterrows():\n",
    "            df_window = df_acct[(df_acc['week'] > window['rolling_start']) & (df_acc['week'] <= window['roling_end'])]\n",
    "            if df_window.empty:\n",
    "                continue\n",
    "            a_stock = df_window['a_stock'].sum()\n",
    "            b_stock = df_window['b_stock'].sum()\n",
    "            c_stock = df_window['c_stock'].sum()\n",
    "            total = a_stock + b_stock + c_stock\n",
    "            a_freq = (df_window['a_stock'] > 0).sum() / df_window['week'].nunique()\n",
    "            b_freq = (df_window['b_stock'] > 0).sum() / df_window['week'].nunique()\n",
    "            #c_freq = (df_window['c_stock'] > 0).sum() / df_window['week'].nunique()\n",
    "            ms_a = a_stock/total if total > 0 else None\n",
    "            ms_b = b_stock/total if total > 0 else None\n",
    "            volume_records.append({\n",
    "                'Account ID': acct,\n",
    "                'rolling_order': window['rolling_order'],\n",
    "                'rolling_4w_a_stock': a_stock,\n",
    "                'rolling_4w_b_stock': b_stock,\n",
    "                'c_stock': c_stock,\n",
    "                #'total_stock': total,\n",
    "                'a_freq': a_freq,\n",
    "                'b_freq': b_freq,\n",
    "                #'c_freq': c_freq,\n",
    "                'rolling_4w_a_ms': ms_a,\n",
    "                'rolling_4w_a_ms': ms_b,\n",
    "            })\n",
    "    volume_partial = pd.DataFrame(volume_records)\n",
    "    volume_r4w_full = account_order_grid.merge(volume_partial, on=['Account ID', 'rolling_order'], how='left')\n",
    "\n",
    "    volume_r4w = volume_r4w_full.merge(rolling_window_df, on='rolling_order', how='left')\n",
    "    metrics_cols = ['rolling_4w_a_stock', 'rolling_4w_b_stock', 'c_stock', 'a_freq', 'b_freq', \n",
    "                    'rolling_4w_a_ms', 'rolling_4w_a_ms']\n",
    "    volume_r4w[metrics_cols] = volume_r4w[metrics_cols].fillna(0)\n",
    "    volume_r4w = volume_r4w.sort_values(['Account ID', 'rolling_order'])\n",
    "    volume_r4w = volume_r4w.merge(df_all[['account_id', 'account_name']].drop_duplicates(),\n",
    "                                left_on='Account ID', right_on='account_id', how='left').drop(columns=['account_id'])\n",
    "    print(df_all['account_id'].nunique(), volume_r4w['Account ID'].nunique(), len(volume_r4w.groupby(['Account ID'])['rolling_order'].nunique().unique().min()))\n",
    "    return volume_r4w\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb83dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spcale up version:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ✅ 建议：开启 pandas 2.x Copy-on-Write（若版本支持），减少不必要拷贝\n",
    "# Recommended: enable pandas 2.x copy-on-write (if your version supports it)\n",
    "pd.options.mode.copy_on_write = True\n",
    "\n",
    "\n",
    "# def build_r4w_metrics(\n",
    "#     df: pd.DataFrame,\n",
    "#     start_wk: str | pd.Timestamp,\n",
    "#     end_wk: str | pd.Timestamp,\n",
    "#     *,\n",
    "#     week_col: str = \"week\",\n",
    "#     id_col: str = \"account_id\",\n",
    "#     name_col: str = \"account_name\",\n",
    "#     a_col: str = \"a_stock\",\n",
    "#     b_col: str = \"b_stock\",\n",
    "#     c_col: str = \"c_stock\",\n",
    "#     freq_denominator: str = \"fixed4\"  # \"fixed4\"（默认，分母恒等于4）或 \"observed\"（分母=窗口内实际观测周数）\n",
    "# ) -> pd.DataFrame:\n",
    "    \n",
    "def build_r4w_metrics(\n",
    "    df,\n",
    "    start_wk,\n",
    "    end_wk,\n",
    "    *,\n",
    "    week_col=\"week\",\n",
    "    id_col=\"account_id\",\n",
    "    name_col=\"account_name\",\n",
    "    a_col=\"a_stock\",\n",
    "    b_col=\"b_stock\",\n",
    "    c_col=\"c_stock\",\n",
    "    freq_denominator=\"fixed4\"\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    \"\"\"\n",
    "    生成以“周五”为窗口终点的 R4W（滚动4周）指标（纯 pandas 向量化、高性能）\n",
    "    Build R4W (rolling 4 weeks) metrics with Friday as window end (pure pandas, vectorized & fast)\n",
    "\n",
    "    输入 Input\n",
    "    -----\n",
    "    df : 包含原始周度数据的 DataFrame；需包含：\n",
    "         DataFrame with weekly rows; must contain:\n",
    "         - id_col（门店/账户ID；e.g., \"account_id\"）\n",
    "         - name_col（门店名；e.g., \"account_name\"）\n",
    "         - week_col（周日期；可为YYYYMMDD/字符串/日期；会对齐到该周“周五”）\n",
    "         - a_col / b_col（A/B品类销量）\n",
    "         - c_col（可选；若不存在将按0处理）\n",
    "    start_wk, end_wk : 统计区间（窗口终点的起/止周五）；如 \"2025-01-03\", \"2025-10-03\"\n",
    "                       Friday range for window ends, e.g. \"2025-01-03\" to \"2025-10-03\"\n",
    "    freq_denominator : \"fixed4\" 使用固定分母4（推荐，稳定）；\"observed\" 使用窗口内实际观测周数作为分母\n",
    "                       Use \"fixed4\" (recommended) or \"observed\" for frequency denominator.\n",
    "\n",
    "    输出 Output\n",
    "    -----\n",
    "    返回含以下列的 DataFrame（只保留窗口终点位于 [start_wk, end_wk] 的周五）：\n",
    "    Returns a DataFrame with Friday window ends within [start_wk, end_wk], including:\n",
    "      - {id_col}, {name_col}, {week_col}（窗口终点 Friday / window end Friday）\n",
    "      - rolling_order（窗口序号，按时间1..N / sequential order 1..N）\n",
    "      - rolling_start, rolling_end（窗口起止；(end-4周, end] / window bounds）\n",
    "      - rolling_window_range_start / rolling_window_range_end（可读范围 / human-readable ranges）\n",
    "      - rolling_4w_a_stock / rolling_4w_b_stock / rolling_4w_c_stock（近4周各品类总量 / 4-week sums）\n",
    "      - total_stock（近4周总量 / 4-week total）\n",
    "      - a_freq / b_freq / c_freq（近4周“>0的周”占比 / share of positive weeks in last 4）\n",
    "      - rolling_4w_a_ms / rolling_4w_b_ms（近4周份额 / market share）\n",
    "    \"\"\"\n",
    "\n",
    "    # ---------- 0) 选择所需列 & 统一周日期到“周五” ----------\n",
    "    # Keep necessary columns only; unify week to the Friday of each week\n",
    "    base_cols = [id_col, name_col, week_col, a_col, b_col]\n",
    "    if c_col in df.columns:\n",
    "        base_cols.append(c_col)\n",
    "    df = df[base_cols].copy()\n",
    "\n",
    "    # 将各种 week 表示（YYYYMMDD/字符串/日期）统一为 Timestamp，并对齐到该周周五\n",
    "    # Normalize 'week' to Timestamp and align to Friday of the week (W-FRI)\n",
    "    if not np.issubdtype(df[week_col].dtype, np.datetime64):\n",
    "        s = df[week_col].astype(str)\n",
    "        is_ymd = s.str.len().eq(8) & s.str.match(r\"^\\d{8}$\")\n",
    "        df.loc[is_ymd, week_col] = pd.to_datetime(s[is_ymd], format=\"%Y%m%d\", errors=\"coerce\")\n",
    "        df.loc[~is_ymd, week_col] = pd.to_datetime(s[~is_ymd], errors=\"coerce\")\n",
    "    df[week_col] = df[week_col].dt.to_period(\"W-FRI\").dt.to_timestamp(\"W-FRI\")\n",
    "\n",
    "    # ---------- 1) 缺失列与类型压缩 ----------\n",
    "    # Fill missing c_col with 0 if absent; compress numeric dtypes\n",
    "    if c_col not in df.columns:\n",
    "        df[c_col] = 0\n",
    "\n",
    "    for col in (a_col, b_col, c_col):\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\").fillna(0).astype(\"Int32\")\n",
    "\n",
    "    # ---------- 2) 生成窗口终点（周五）序列 ----------\n",
    "    # Build list of Friday window ends within [start_wk, end_wk]\n",
    "    start_wk = pd.to_datetime(start_wk)\n",
    "    end_wk = pd.to_datetime(end_wk)\n",
    "    friday_ends = pd.date_range(start=start_wk, end=end_wk, freq=\"W-FRI\")\n",
    "\n",
    "    # 由于 rolling(4) 需要往前3周的数据，扩展一个最早日期 earliest_needed\n",
    "    # For rolling(4), we need 3 more prior weeks\n",
    "    earliest_needed = friday_ends.min() - pd.Timedelta(weeks=3)\n",
    "\n",
    "    # ---------- 3) 聚合为“账号×周五”的周表，并对每个账号补齐完整周历 ----------\n",
    "    # Aggregate to weekly (Friday) per account, then reindex each account to a full Friday calendar\n",
    "    weekly = (\n",
    "        df.groupby([id_col, name_col, week_col], as_index=False)[[a_col, b_col, c_col]].sum()\n",
    "    )\n",
    "\n",
    "    # def _reindex_one(g: pd.DataFrame) -> pd.DataFrame:\n",
    "    #     idx = pd.date_range(start=earliest_needed, end=end_wk, freq=\"W-FRI\")\n",
    "    #     g = g.set_index(week_col).reindex(idx, fill_value=0)\n",
    "    #     g.index.name = week_col\n",
    "    #     g = g.reset_index()\n",
    "    #     g[id_col] = g[id_col].iloc[0]\n",
    "    #     g[name_col] = g[name_col].iloc[0]\n",
    "    #     return g[[id_col, name_col, week_col, a_col, b_col, c_col]]\n",
    "    def _reindex_one(g: pd.DataFrame) -> pd.DataFrame:\n",
    "    # 先从真实行取出 id/name 常量，避免被补齐行的 0 覆盖\n",
    "        _id   = g[id_col].iloc[0]\n",
    "        _name = g[name_col].iloc[0]\n",
    "\n",
    "        idx = pd.date_range(start=earliest_needed, end=end_wk, freq=\"W-FRI\")\n",
    "\n",
    "    # 只对数值列做补齐；不要对 id/name 做 fill_value=0\n",
    "        g_vals = (\n",
    "            g[[week_col, a_col, b_col, c_col]]\n",
    "            .set_index(week_col)\n",
    "            .reindex(idx, fill_value=0)\n",
    "            .reset_index()\n",
    "            .rename(columns={\"index\": week_col})\n",
    "    )\n",
    "\n",
    "    # 回写 id/name 常量\n",
    "        g_vals[id_col] = _id\n",
    "        g_vals[name_col] = _name\n",
    "\n",
    "        return g_vals[[id_col, name_col, week_col, a_col, b_col, c_col]]\n",
    "\n",
    "    weekly_full = (\n",
    "        weekly.groupby([id_col, name_col], group_keys=False)\n",
    "              .apply(_reindex_one)\n",
    "              .reset_index(drop=True)\n",
    "              .sort_values([id_col, week_col])\n",
    "    )\n",
    "\n",
    "    # ---------- 4) 计算 R4W 的 sum / freq / ms（全向量化） ----------\n",
    "    # Compute rolling-4-week sums, positive frequencies, and market shares (vectorized)\n",
    "    gb = weekly_full.groupby(id_col, group_keys=False)\n",
    "\n",
    "    # 近4周 sum（A/B/C）\n",
    "    a_4 = gb[a_col].rolling(4, min_periods=1).sum().reset_index(drop=True)\n",
    "    b_4 = gb[b_col].rolling(4, min_periods=1).sum().reset_index(drop=True)\n",
    "    c_4 = gb[c_col].rolling(4, min_periods=1).sum().reset_index(drop=True)\n",
    "\n",
    "    weekly_full[\"rolling_4w_a_stock\"] = a_4.astype(\"float\")\n",
    "    weekly_full[\"rolling_4w_b_stock\"] = b_4.astype(\"float\")\n",
    "    weekly_full[\"rolling_4w_c_stock\"] = c_4.astype(\"float\")\n",
    "    weekly_full[\"total_stock\"] = weekly_full[\"rolling_4w_a_stock\"] + weekly_full[\"rolling_4w_b_stock\"] + weekly_full[\"rolling_4w_c_stock\"]\n",
    "\n",
    "    # 近4周“有货周”计数（>0）/ count of positive weeks in the last 4\n",
    "    a_pos = gb[a_col].apply(lambda s: (s > 0).rolling(4, min_periods=1).sum()).reset_index(drop=True)\n",
    "    b_pos = gb[b_col].apply(lambda s: (s > 0).rolling(4, min_periods=1).sum()).reset_index(drop=True)\n",
    "    c_pos = gb[c_col].apply(lambda s: (s > 0).rolling(4, min_periods=1).sum()).reset_index(drop=True)\n",
    "\n",
    "    # 频率分母：fixed4 = 4；observed = 窗口内实际观测周数（首个窗口可能<4）\n",
    "    # Frequency denominator: fixed4=4; observed=actual observed weeks in the window (first windows may be <4)\n",
    "    if freq_denominator == \"observed\":\n",
    "        denom = (gb[week_col].cumcount() + 1).clip(upper=4)\n",
    "    else:\n",
    "        denom = pd.Series(4, index=weekly_full.index)\n",
    "\n",
    "    weekly_full[\"a_freq\"] = (a_pos / denom).astype(\"float\")\n",
    "    weekly_full[\"b_freq\"] = (b_pos / denom).astype(\"float\")\n",
    "    weekly_full[\"c_freq\"] = (c_pos / denom).astype(\"float\")\n",
    "\n",
    "    # 近4周份额（market share）；total=0 时置为 0，避免 NaN/inf\n",
    "    # 4-week market shares; if total==0, set to 0.0\n",
    "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "        weekly_full[\"rolling_4w_a_ms\"] = np.where(\n",
    "            weekly_full[\"total_stock\"] > 0,\n",
    "            weekly_full[\"rolling_4w_a_stock\"] / weekly_full[\"total_stock\"],\n",
    "            0.0,\n",
    "        )\n",
    "        weekly_full[\"rolling_4w_b_ms\"] = np.where(\n",
    "            weekly_full[\"total_stock\"] > 0,\n",
    "            weekly_full[\"rolling_4w_b_stock\"] / weekly_full[\"total_stock\"],\n",
    "            0.0,\n",
    "        )\n",
    "\n",
    "    # ---------- 5) 仅保留窗口终点位于 [start_wk, end_wk] 的周五，并生成 rolling_order ----------\n",
    "    # Keep only Friday ends within [start_wk, end_wk] and add rolling_order\n",
    "    out = weekly_full[weekly_full[week_col].isin(friday_ends)].copy()\n",
    "    out = out.sort_values([id_col, week_col])\n",
    "\n",
    "    ro_map = {d: i + 1 for i, d in enumerate(sorted(friday_ends))}\n",
    "    out[\"rolling_order\"] = out[week_col].map(ro_map).astype(\"Int32\")\n",
    "\n",
    "    # 窗口边界与范围（(end-4周, end]）\n",
    "    # Window bounds and human-readable ranges\n",
    "    out[\"rolling_end\"] = out[week_col]\n",
    "    out[\"rolling_start\"] = out[\"rolling_end\"] - pd.Timedelta(weeks=4)\n",
    "    out[\"rolling_window_range_start\"] = (\n",
    "        out[\"rolling_start\"].dt.strftime(\"%Y-%m-%d\") + \" to \" + out[\"rolling_end\"].dt.strftime(\"%Y-%m-%d\")\n",
    "    )\n",
    "    out[\"rolling_window_range_end\"] = (\n",
    "        out[\"rolling_end\"].dt.strftime(\"%Y-%m-%d\") + \" to \" + (out[\"rolling_end\"] + pd.Timedelta(weeks=4)).dt.strftime(\"%Y-%m-%d\")\n",
    "    )\n",
    "\n",
    "    # 输出列顺序 / Final column order\n",
    "    keep_cols = [\n",
    "        id_col, name_col, week_col, \"rolling_order\",\n",
    "        \"rolling_start\", \"rolling_end\",\n",
    "        \"rolling_window_range_start\", \"rolling_window_range_end\",\n",
    "        \"rolling_4w_a_stock\", \"rolling_4w_b_stock\", \"rolling_4w_c_stock\",\n",
    "        \"total_stock\", \"a_freq\", \"b_freq\", \"c_freq\",\n",
    "        \"rolling_4w_a_ms\", \"rolling_4w_b_ms\",\n",
    "    ]\n",
    "    out = out.loc[:, keep_cols]\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1e15f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6579fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_r4w = build_r4w_metrics(\n",
    "    df_all,\n",
    "    start_wk=\"2024-05-01\",   # 不必是周五；函数会自动对齐到该周“周五”\n",
    "    end_wk=\"2025-08-29\",     # 这是周五，完美\n",
    "    freq_denominator=\"fixed4\"  # ✅ 正确参数名\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d161551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original Change Table Version\n",
    "def get_change_r4w(volume_r4w):\n",
    "    change_records = []\n",
    "    volume_r4w['rolling_window_range'] = (\n",
    "        volume_r4w['rolling_start'].dt.strftime('%Y-%m-%d') + \n",
    "        ' to ' \n",
    "        + volume_r4w['rolling_end'].dt.strftime('%Y-%m-%d')\n",
    "    )\n",
    "\n",
    "    for acct, df_acct in volume_r4w.groupby('Account ID'):\n",
    "        df_acct = df_acct.sort_values('rolling_order').reset_index(drop=True)\n",
    "        for i in range(1, len(df_acct)):\n",
    "            prev = df_acct.iloc[i-1]\n",
    "            curr = df_acct.iloc[i]\n",
    "\n",
    "            def pct(now, prev): return round((now - prev)/prev, 2) if pd.notnull(prev) and prev != 0 else 0\n",
    "\n",
    "            change_records.append({\n",
    "                'Account ID': acct,\n",
    "                'rolling_order': curr['rolling_order'],\n",
    "                'rolling_window_range_start': prev['rolling_window_range'],\n",
    "                'rolling_window_range_end': curr['rolling_window_range'],\n",
    "                'change_4w_a_stock': pct(curr['rolling_4w_a_stock'], prev['rolling_4w_a_stock']),\n",
    "                'change_4w_b_stock': pct(curr['rolling_4w_b_stock'], prev['rolling_4w_b_stock']),\n",
    "                'change_c_stock': pct(curr['c_stock'] , prev['c_stock']),\n",
    "                'change_a_freq': pct(curr['a_freq'] , prev['a_freq']),\n",
    "                'change_b_freq': pct(curr['b_freq'] , prev['b_freq']),\n",
    "                'change_4w_a_ms': pct(curr['rolling_4w_a_ms'] , prev['rolling_4w_a_ms']),\n",
    "                'change_4w_b_ms': pct(curr['rolling_4w_b_ms'] , prev['rolling_4w_b_ms']),\n",
    "            })\n",
    "    change_r4w = pd.DataFrame(change_records)\n",
    "\n",
    "    first_b_stocking_orders = (volume_r4w[(volume_r4w['rolling_4w_b_ms'] > 0)]\n",
    "                               .groupby('Account ID')['rolling_order']\n",
    "                               .min()\n",
    "                               .reset_index()\n",
    "                               .rename(columns={'rolling_order':'first_b_stock_rw'}))\n",
    "    fallback_orders = (volume_r4w.groupby('Account ID')['rolling_order'].max().reset_index()\n",
    "                          .rename(columns={'rolling_order':'fallback_order'}))\n",
    "    first_b_stocking_orders = fallback_orders.merge(first_b_stocking_orders, on='Account ID', how='left')\n",
    "    first_b_stocking_orders['first_b_stock_rw'] = first_b_stocking_orders['first_b_stock_rw'].fillna(first_b_stocking_orders['fallback_order'])\n",
    "    change_r4w = change_r4w.merge(first_b_stocking_orders[['Account ID', 'first_b_stock_rw']],\n",
    "                                  left_on='Account ID', right_on='Account ID', how='left')\n",
    "    change_r4w = change_r4w.merge(df_all[['Account ID', 'account_name']].drop_duplicates(),\n",
    "                                left_on='Account ID', right_on='Account ID', how='left')\n",
    "    return change_r4w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50480832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def get_change_r4w_fast(\n",
    "    volume_r4w: pd.DataFrame,\n",
    "    *,\n",
    "    id_col: str = \"account_id\",\n",
    "    name_col: str = \"account_name\",\n",
    "    order_col: str = \"rolling_order\",\n",
    "    start_col: str = \"rolling_start\",\n",
    "    end_col: str = \"rolling_end\",\n",
    "    # R4W 指标列（与 build_r4w_metrics 输出保持一致）\n",
    "    a4_col: str = \"rolling_4w_a_stock\",\n",
    "    b4_col: str = \"rolling_4w_b_stock\",\n",
    "    c4_col: str = \"rolling_4w_c_stock\",\n",
    "    a_freq_col: str = \"a_freq\",\n",
    "    b_freq_col: str = \"b_freq\",\n",
    "    c_freq_col: str = \"c_freq\",\n",
    "    a_ms_col: str = \"rolling_4w_a_ms\",\n",
    "    b_ms_col: str = \"rolling_4w_b_ms\",\n",
    "    # 是否保留绝对变化（delta）列\n",
    "    keep_delta: bool = False,\n",
    "    # 百分比保留小数位\n",
    "    round_ndigits: int = 2,\n",
    "):\n",
    "    \"\"\"\n",
    "    生成“相邻滚动窗变化表”（相同账号、相邻 rolling_order 的百分比变化）。\n",
    "    Vectorized change table between consecutive rolling windows per account.\n",
    "\n",
    "    变化定义（默认）/ Default change definition:\n",
    "        pct_change = (curr - prev) / prev\n",
    "        若 prev==0 或 NaN 则记为 0（避免 inf/NaN）\n",
    "\n",
    "    输出列 / Output columns:\n",
    "      - id/name/order\n",
    "      - rolling_window_range_start: 上一个窗口的 [start, end] 字符串\n",
    "      - rolling_window_range_end  : 当前窗口的   [start, end] 字符串\n",
    "      - change_4w_a_stock / change_4w_b_stock / change_4w_c_stock\n",
    "      - change_a_freq / change_b_freq / change_c_freq\n",
    "      - change_4w_a_ms / change_4w_b_ms\n",
    "      - （可选）*_delta 绝对变化列\n",
    "      - first_b_stock_rw: 每账号首次出现 B 份额>0 的 rolling_order（缺失回退为该账号最大 rolling_order）\n",
    "    \"\"\"\n",
    "\n",
    "    df = volume_r4w.copy()\n",
    "\n",
    "    # ---------- 0) 安全排序 / sort to ensure consecutive windows ----------\n",
    "    df = df.sort_values([id_col, order_col], kind=\"mergesort\").reset_index(drop=True)\n",
    "\n",
    "    # ---------- 1) 生成窗口范围字符串（上、下两个窗） ----------\n",
    "    # Build readable ranges first\n",
    "    rng_str = (\n",
    "        df[start_col].dt.strftime(\"%Y-%m-%d\")\n",
    "        + \" to \"\n",
    "        + df[end_col].dt.strftime(\"%Y-%m-%d\")\n",
    "    )\n",
    "    df[\"__range_str\"] = rng_str\n",
    "\n",
    "    # 上一个窗口（同账号，order-1）的范围与指标 → 使用 groupby().shift(1)\n",
    "    # Previous window (same account) via shift(1)\n",
    "    gb = df.groupby(id_col, group_keys=False)\n",
    "\n",
    "    prev_range = gb[\"__range_str\"].shift(1)\n",
    "    prev_order = gb[order_col].shift(1)\n",
    "\n",
    "    # 需要变化的字段列表（在这里统一维护，易扩展）\n",
    "    metric_cols = [\n",
    "        a4_col, b4_col, c4_col,\n",
    "        a_freq_col, b_freq_col, c_freq_col,\n",
    "        a_ms_col, b_ms_col,\n",
    "    ]\n",
    "\n",
    "    # 为每个度量生成 prev、delta、pct_change\n",
    "    for col in metric_cols:\n",
    "        df[f\"__prev_{col}\"]  = gb[col].shift(1)\n",
    "        df[f\"__delta_{col}\"] = df[col] - df[f\"__prev_{col}\"]\n",
    "        # 百分比变化： (curr-prev)/prev，prev==0 or NaN → 0\n",
    "        prev = df[f\"__prev_{col}\"].astype(\"float\")\n",
    "        curr = df[col].astype(\"float\")\n",
    "        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "            pct = np.where((prev != 0) & (~np.isnan(prev)),\n",
    "                           (curr - prev) / prev,\n",
    "                           0.0)\n",
    "        df[f\"__pct_{col}\"] = np.round(pct, round_ndigits)\n",
    "\n",
    "    # 只保留具有“前一个窗口”的行（rolling_order >= 2）\n",
    "    df_keep = df[prev_order.notna()].copy()\n",
    "\n",
    "    # ---------- 2) 组装输出 ----------\n",
    "    out = pd.DataFrame({\n",
    "        id_col:   df_keep[id_col].values,\n",
    "        name_col: df_keep[name_col].values,\n",
    "        order_col: df_keep[order_col].astype(\"Int32\").values,\n",
    "        \"rolling_window_range_start\": prev_range.loc[df_keep.index].values,  # 上一窗口的范围\n",
    "        \"rolling_window_range_end\":   df_keep[\"__range_str\"].values,         # 当前窗口的范围\n",
    "    })\n",
    "\n",
    "    # 映射列名：原指标名 → 输出变化列名\n",
    "    rename_map = {\n",
    "        a4_col:      \"change_4w_a_stock\",\n",
    "        b4_col:      \"change_4w_b_stock\",\n",
    "        c4_col:      \"change_4w_c_stock\",\n",
    "        a_freq_col:  \"change_a_freq\",\n",
    "        b_freq_col:  \"change_b_freq\",\n",
    "        c_freq_col:  \"change_c_freq\",\n",
    "        a_ms_col:    \"change_4w_a_ms\",\n",
    "        b_ms_col:    \"change_4w_b_ms\",\n",
    "    }\n",
    "\n",
    "    # 添加百分比变化列\n",
    "    for col in metric_cols:\n",
    "        out[rename_map[col]] = df_keep[f\"__pct_{col}\"].values\n",
    "\n",
    "    # （可选）添加绝对变化列（便于做阈值/分段）\n",
    "    if keep_delta:\n",
    "        for col in metric_cols:\n",
    "            out[rename_map[col].replace(\"change_\", \"delta_\")] = df_keep[f\"__delta_{col}\"].values\n",
    "\n",
    "    # ---------- 3) 计算 first_b_stock_rw（首次 B 份额>0 的 rolling_order） ----------\n",
    "    # First rolling_order per account where b_ms_col > 0\n",
    "    first_b = (\n",
    "        volume_r4w.loc[volume_r4w[b_ms_col] > 0, [id_col, order_col]]\n",
    "        .groupby(id_col, as_index=False)[order_col]\n",
    "        .min()\n",
    "        .rename(columns={order_col: \"first_b_stock_rw\"})\n",
    "    )\n",
    "\n",
    "    # 如果某账号从未出现 B 份额>0，则回退为该账号最后一次 rolling_order\n",
    "    fallback = (\n",
    "        volume_r4w.groupby(id_col, as_index=False)[order_col]\n",
    "        .max()\n",
    "        .rename(columns={order_col: \"fallback_order\"})\n",
    "    )\n",
    "\n",
    "    first_b = fallback.merge(first_b, on=id_col, how=\"left\")\n",
    "    first_b[\"first_b_stock_rw\"] = first_b[\"first_b_stock_rw\"].fillna(first_b[\"fallback_order\"]).astype(\"Int32\")\n",
    "\n",
    "    out = out.merge(first_b[[id_col, \"first_b_stock_rw\"]], on=id_col, how=\"left\")\n",
    "\n",
    "    # ---------- 4) 清理临时列 ----------\n",
    "    # （这里 out 已经是最终表，无需保留临时列）\n",
    "    # 如果你希望保留更多上下文（如 curr/prev 原值），可以在 out 里额外 merge。\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d1ea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_r4w = get_change_r4w_fast(volume_r4w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760e3b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loop version\n",
    "\n",
    "def get_matrix(change_r4w, wolume_r4w):\n",
    "    change_cols = ['change_4w_a_ms', 'change_4w_a_stock', 'change_a_freq']\n",
    "    feature_records = []\n",
    "    for acct, group in change_r4w.groupby('Account ID'):\n",
    "        row={'Account ID': acct}\n",
    "        first_b_stock_rw = group['first_b_stock_rw'].iloc[0]\n",
    "        before = group[group['rolling_order'] < first_b_stock_rw]\n",
    "        after = group[group['rolling_order'] >= first_b_stock_rw]\n",
    "        for col in change_cols:\n",
    "            row[f'{col}_neg_before'] = (before[col] < 0).sum()\n",
    "            row[f'{col}_pos_before'] = (before[col] > 0).sum()\n",
    "            row[f'{col}_no_change_before'] = (before[col] == 0).sum()\n",
    "            row[f'{col}_neg_after'] = (after[col] < 0).sum()\n",
    "            row[f'{col}_pos_after'] = (after[col] > 0).sum()\n",
    "            row[f'{col}_no_change_after'] = (after[col] == 0).sum()\n",
    "            row[f'{col}_volatility_before'] = before[col].std()\n",
    "            row[f'{col}_volatility_after'] = after[col].std()\n",
    "            row[f'{col}_first_drop_order'] = group.loc[group[col] < 0, 'rolling_order'].min() if not group.loc[group[col] < 0].empty else np.nan\n",
    "            row[f'{col}_first_rise_order'] = group.loc[group[col] > 0, 'rolling_order'].min() if not group.loc[group[col] > 0].empty else np.nan\n",
    "        feature_records.append(row)\n",
    "    df_change_features = pd.DataFrame(feature_records)\n",
    "\n",
    "    # b wine features (positive count, volatility)\n",
    "    b_change_cols = ['change_4w_b_ms', 'change_4w_b_stock', 'change_b_freq']\n",
    "    b_feature_records = []\n",
    "    for acct, group in change_r4w.groupby('Account ID'):\n",
    "        row={'Account ID': acct}\n",
    "        for col in b_change_cols:\n",
    "            row[f'{col}_pos_count'] = (group[col] > 0).sum()\n",
    "            row[f'{col}_volatility'] = group[col].std()\n",
    "        b_feature_records.append(row)\n",
    "    df_b_change_summary = pd.DataFrame(b_feature_records)\n",
    "\n",
    "    # consecutive_streaks\n",
    "    def count_consecutive_streaks(series, condition, threshold):\n",
    "        streak = 0\n",
    "        count = 0\n",
    "        for val in series:\n",
    "            if pd.notnull(val) and condition(val):\n",
    "                streak += 1\n",
    "                if streak == threshold:\n",
    "                    count += 1\n",
    "                    streak -=1  # allow overlapping streaks\n",
    "            else:\n",
    "                streak = 0\n",
    "        return count\n",
    "    records = []\n",
    "    for acct, group in change_r4w.groupby('Account ID'):\n",
    "        row = {'Account ID': acct}\n",
    "        first_b_order = group['first_b_stock_rw'].iloc[0]\n",
    "        before = group[group['rolling_order'] < first_b_order]\n",
    "        after = group[group['rolling_order'] >= first_b_order]\n",
    "        row['a_stocking_3fall_before_b'] = count_consecutive_streaks(before['change_4w_a_stock'], lambda x: x < 0, 3)\n",
    "        row['a_ms_3fall_after_b'] = count_consecutive_streaks(after['change_4w_a_ms'], lambda x: x < 0, 3)\n",
    "        row['a_stocking_4fall_before_b'] = count_consecutive_streaks(before['change_4w_a_stock'], lambda x: x < 0, 4)\n",
    "        row['a_ms_4fall_after_b'] = count_consecutive_streaks(after['change_4w_a_ms'], lambda x: x < 0, 4)\n",
    "        row['a_stocking_5fall_before_b'] = count_consecutive_streaks(before['change_4w_a_stock'], lambda x: x < 0, 5)\n",
    "        row['a_ms_5fall_after_b'] = count_consecutive_streaks(after['change_4w_a_ms'], lambda x: x < 0, 5)\n",
    "        records.append(row)\n",
    "    df_a_streaks = pd.DataFrame(records)\n",
    "\n",
    "    #Merge all features + generate target\n",
    "    df_features = df_change_features.merge(df_b_change_summary, on='Account ID', how='left')\n",
    "    df_features = df_features.merge(df_a_streaks, on='Account ID', how='left')\n",
    "\n",
    "    df_modeling = df_features.merge(df_all[['account_id', 'account_name']].drop_duplicates(),\n",
    "                                  left_on='Account ID', right_on='account_id', how='left')\n",
    "    return df_modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4a983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# =========================\n",
    "# Scalling anbd Accelerated feature builder v2.1\n",
    "# =========================\n",
    "# Upgrads:\n",
    "# - Features reproduction：neg/pos/zero, volatility, first_drop/rise\n",
    "# - B Metrics：pos_count, volatility\n",
    "# - A Metrics：before_B, a_stock consecutive decling 3/4/5；after_B, a_ms consecutive decling 3/4/5\n",
    "# - Support cutoff（only keep <= cutoff rolling windows）\n",
    "# - Includes before_B and after_B（as first_b_stock_rw cutoff）\n",
    "\n",
    "def build_feature_matrix_fast(\n",
    "    change_r4w: pd.DataFrame,\n",
    "    volume_r4w: pd.DataFrame,\n",
    "    cutoff: str | pd.Timestamp,\n",
    "    *,\n",
    "    id_col=\"Account ID\",\n",
    "    name_col_in_volume=\"account_name\",\n",
    "    order_col=\"rolling_order\",\n",
    "    firstb_col=\"first_b_stock_rw\",\n",
    "    #  change columns (a and b sides)\n",
    "    a_change_cols=(\"change_4w_a_ms\", \"change_4w_a_stock\", \"change_a_freq\"),\n",
    "    b_change_cols=(\"change_4w_b_ms\", \"change_4w_b_stock\", \"change_b_freq\"),\n",
    "    # \n",
    "    # get end date from change_r4w (default parse from 'rolling_window_range_end' start date)\n",
    "    end_range_col=\"rolling_window_range_end\",\n",
    "):\n",
    "    \"\"\"\n",
    "    构建特征矩阵（含 before_B & after_B），只使用 <= cutoff 的窗口。\n",
    "    Build feature matrix with before/after-B splits, using windows with end <= cutoff.\n",
    "    \"\"\"\n",
    "\n",
    "    df = change_r4w.copy()\n",
    "\n",
    "    # ---------- 0) 截止日期过滤（尽量不依赖额外列；从 range 字符串解析 end 日期） ----------\n",
    "    # ---------- 0) Cutoff filtering (parse end date from range string to avoid extra merges) ----------\n",
    "    # e.g. 'rolling_window_range_end' like '2025-01-03 to 2025-01-31' → 取前半段 '2025-01-03'\n",
    "    # e.g. 'rolling_window_range_end' format: '2025-01-03 to 2025-01-31' → take first part '2025-01-03'\n",
    "    if end_range_col in df.columns:\n",
    "        end_dates = pd.to_datetime(df[end_range_col].astype(str).str.split(\" to \").str[0], errors=\"coerce\")\n",
    "    else:\n",
    "        # 后备：若无该列，可改为用 volume_r4w merge end 周五（需要确保两边可 join）\n",
    "        # Fallback: if missing, consider merging end week from volume_r4w (ensure joinable)\n",
    "        raise ValueError(f\"Column '{end_range_col}' not found in change_r4w; please provide an end date column or adjust parsing.\")\n",
    "\n",
    "    cutoff = pd.to_datetime(cutoff)\n",
    "    df = df.loc[end_dates.le(cutoff)].copy()\n",
    "\n",
    "    # 必要列存在性校验\n",
    "    # Necessary columns check\n",
    "    need_cols = [id_col, order_col, firstb_col, *a_change_cols, *b_change_cols]\n",
    "    missing = [c for c in need_cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns in change_r4w: {missing}\")\n",
    "\n",
    "    # ---------- 1) 相位标记 phase flags ----------\n",
    "    # ---------- 1) Phase flags ----------\n",
    "    # before_B / after_B\n",
    "    df[\"__before\"] = df[order_col] < df[firstb_col]\n",
    "    df[\"__after\"]  = df[order_col] >= df[firstb_col]\n",
    "\n",
    "    # ---------- 2) A 面：before/after 的 neg/pos/zero 计数 + volatility ----------\n",
    "    # -----------2) A side: before/after neg/pos/zero counts + volatility ----------\n",
    "    # 用掩码向量化：在不属于该相位的行置为 False / NaN，再 groupby sum/std\n",
    "    # Use masks to vectorize: set non-phase rows to False/NaN, then groupby sum/std\n",
    "    out_parts = []\n",
    "\n",
    "    g = df.groupby(id_col, group_keys=True)\n",
    "\n",
    "    def _phase_counts_and_vol(col: str, phase_col: str, phase_name: str) -> pd.DataFrame:\n",
    "        m = df[phase_col].to_numpy()       # True/False\n",
    "        vals = df[col].to_numpy()\n",
    "\n",
    "        # counts\n",
    "        neg_ct = g.apply(lambda x: ((x[col] < 0) & x[phase_col]).sum()).rename(f\"{col}_neg_{phase_name}\")\n",
    "        pos_ct = g.apply(lambda x: ((x[col] > 0) & x[phase_col]).sum()).rename(f\"{col}_pos_{phase_name}\")\n",
    "        zer_ct = g.apply(lambda x: ((x[col] == 0) & x[phase_col]).sum()).rename(f\"{col}_no_change_{phase_name}\")\n",
    "\n",
    "        # volatility (std)\n",
    "        # 用 where 只保留该相位的数据，其他相位设为 NaN，再按组 std\n",
    "        # use where to keep only phase data, set others to NaN, then group std\n",
    "        phase_vals = np.where(m, vals, np.nan)\n",
    "        tmp = df[[id_col]].copy()\n",
    "        tmp[f\"__{col}_phase\"] = phase_vals\n",
    "        vol = tmp.groupby(id_col, as_index=True)[f\"__{col}_phase\"].std(ddof=1).rename(f\"{col}_volatility_{phase_name}\")\n",
    "\n",
    "        return pd.concat([neg_ct, pos_ct, zer_ct, vol], axis=1)\n",
    "\n",
    "    for col in a_change_cols:\n",
    "        out_parts.append(_phase_counts_and_vol(col, \"__before\", \"before\"))\n",
    "        out_parts.append(_phase_counts_and_vol(col, \"__after\",  \"after\"))\n",
    "\n",
    "    df_change_features = pd.concat(out_parts, axis=1)\n",
    "    df_change_features.index.name = id_col\n",
    "    df_change_features = df_change_features.reset_index()\n",
    "\n",
    "    # ---------- 3) first_drop / first_rise（基于全部窗口，不分相位） ----------\n",
    "    # ---------- 3) first_drop / first_rise (across all windows, no phase split) ----------\n",
    "    # 注意：这里按你的原逻辑，是在“所有窗口”上取 min(rolling_order)\n",
    "    # Note: according to your original logic, we take min(rolling_order) across all windows\n",
    "    fr_parts = []\n",
    "    for col in (*a_change_cols, *b_change_cols):\n",
    "        mask_drop = df[col] < 0\n",
    "        mask_rise = df[col] > 0\n",
    "        first_drop = df.loc[mask_drop].groupby(id_col)[order_col].min().rename(f\"{col}_first_drop_order\")\n",
    "        first_rise = df.loc[mask_rise].groupby(id_col)[order_col].min().rename(f\"{col}_first_rise_order\")\n",
    "        fr_parts.append(first_drop)\n",
    "        fr_parts.append(first_rise)\n",
    "    df_firsts = pd.concat(fr_parts, axis=1).reset_index()\n",
    "\n",
    "    # ---------- 4) B 面汇总（不分相位）：pos_count & volatility ----------\n",
    "    # ---------- 4) B side summary (no phase split): pos_count & volatility ----------\n",
    "    b_parts = []\n",
    "    for col in b_change_cols:\n",
    "        pos_count = df.groupby(id_col)[col].apply(lambda s: (s > 0).sum()).rename(f\"{col}_pos_count\")\n",
    "        vol = df.groupby(id_col)[col].std(ddof=1).rename(f\"{col}_volatility\")\n",
    "        b_parts.append(pos_count)\n",
    "        b_parts.append(vol)\n",
    "    df_b_summary = pd.concat(b_parts, axis=1).reset_index()\n",
    "\n",
    "    # ---------- 5) 连续串（小规模按组 apply，窗口≤52/较短 → 可接受） ----------\n",
    "    # ---------- 5) Consecutive streaks (small-scale group apply, windows ≤52/short → acceptable) ----------\n",
    "    # 允许重叠 / allow overlapping\n",
    "    # 计算 k 连续负增长的次数 /count of k consecutive negative changes\n",
    "    def _count_consecutive_neg(x: pd.Series, k: int) -> int:\n",
    "        arr = x.to_numpy()\n",
    "        n = 0\n",
    "        streak = 0\n",
    "        for v in arr:\n",
    "            if pd.notna(v) and (v < 0):\n",
    "                streak += 1\n",
    "                if streak == k:\n",
    "                    n += 1\n",
    "                    streak -= 1  # allow overlapping\n",
    "            else:\n",
    "                streak = 0\n",
    "        return n\n",
    "\n",
    "    # A: before_B 的 a_stock 3/4/5 连跌\n",
    "    # A: a_stocking_3/4/5 fall before_B\n",
    "    # A: after_B  的 a_ms    3/4/5 连跌\n",
    "    # A: a_ms_3/4/5 fall after_B\n",
    "    # 先按相位切分再聚合\n",
    "    # Then split by phase and aggregate\n",
    "    def _streak_block(group: pd.DataFrame) -> pd.Series:\n",
    "        out = {}\n",
    "        g_before = group.loc[group[\"__before\"]]\n",
    "        g_after  = group.loc[group[\"__after\"]]\n",
    "\n",
    "        # before_B streaks on change_4w_a_stock\n",
    "        for K in (3, 4, 5):\n",
    "            out[f\"a_stocking_{K}fall_before_b\"] = _count_consecutive_neg(g_before[\"change_4w_a_stock\"], K)\n",
    "\n",
    "        # after_B streaks on change_4w_a_ms\n",
    "        for K in (3, 4, 5):\n",
    "            out[f\"a_ms_{K}fall_after_b\"] = _count_consecutive_neg(g_after[\"change_4w_a_ms\"], K)\n",
    "\n",
    "        return pd.Series(out)\n",
    "\n",
    "    df_streaks = df.groupby(id_col, as_index=False).apply(_streak_block).reset_index().rename(columns={id_col: id_col})\n",
    "\n",
    "    # ---------- 6) 合并所有特征 ----------\n",
    "    # ---------- 6) Merge all features ----------\n",
    "    features = (\n",
    "        df_change_features\n",
    "        .merge(df_firsts,    on=id_col, how=\"left\")\n",
    "        .merge(df_b_summary, on=id_col, how=\"left\")\n",
    "        .merge(df_streaks,   on=id_col, how=\"left\")\n",
    "    )\n",
    "\n",
    "    # ---------- 7) 追加账户名称 ----------\n",
    "    # ---------- 7) Append account names ----------\n",
    "    if (name_col_in_volume in volume_r4w.columns) and (id_col in change_r4w.columns):\n",
    "        names = volume_r4w[[name_col_in_volume]].copy()\n",
    "        # volume_r4w 里通常有 'account_id'，但当前主键是 'Account ID'，统一一下映射：\n",
    "        # volume_r4w usually has 'account_id', but current key is 'Account ID', unify mapping:\n",
    "        # 尝试从 volume_r4w 找到 id 的列名\n",
    "        # Try to find the id column name from volume_r4w\n",
    "        id_candidates = [c for c in volume_r4w.columns if c.lower() in (\"account id\", \"account_id\", \"id\")]\n",
    "        if id_candidates:\n",
    "            id_in_volume = id_candidates[0]\n",
    "            names = volume_r4w[[id_in_volume, name_col_in_volume]].drop_duplicates()\n",
    "            names = names.rename(columns={id_in_volume: id_col})\n",
    "            features = features.merge(names, on=id_col, how=\"left\")\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "# =============================\n",
    "# 便捷函数：一键生成 Train/Valid\n",
    "# =============================\n",
    "# ==========================================================\n",
    "# Convenience function: build Train/Valid in one call\n",
    "# ==========================================================\n",
    "def build_train_valid_features(\n",
    "    change_r4w: pd.DataFrame,\n",
    "    volume_r4w: pd.DataFrame,\n",
    "    *,\n",
    "    cutoff_train=\"2025-08-29\",\n",
    "    cutoff_valid=\"2025-10-03\",\n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    生成两套特征矩阵：\n",
    "      - Train: 仅使用 <= cutoff_train 的窗口\n",
    "      - Valid: 仅使用 <= cutoff_valid 的窗口（天然 out-of-fold 相对更近时段）\n",
    "    \"\"\"\n",
    "    feat_train = build_feature_matrix_fast(change_r4w, volume_r4w, cutoff_train, **kwargs)\n",
    "    feat_valid = build_feature_matrix_fast(change_r4w, volume_r4w, cutoff_valid, **kwargs)\n",
    "    return feat_train, feat_valid\n",
    "\n",
    "\n",
    "# ======================\n",
    "#  How to use\n",
    "# ======================\n",
    "# feat_train, feat_valid = build_train_valid_features(\n",
    "#     change_r4w,\n",
    "#     volume_r4w,\n",
    "#     cutoff_train=\"2025-08-29\",\n",
    "#     cutoff_valid=\"2025-10-03\",\n",
    "#     id_col=\"Account ID\",\n",
    "#     name_col_in_volume=\"account_name\",\n",
    "#     order_col=\"rolling_order\",\n",
    "#     firstb_col=\"first_b_stock_rw\",\n",
    "#     a_change_cols=(\"change_4w_a_ms\", \"change_4w_a_stock\", \"change_a_freq\"),\n",
    "#     b_change_cols=(\"change_4w_b_ms\", \"change_4w_b_stock\", \"change_b_freq\"),\n",
    "#     end_range_col=\"rolling_window_range_end\",   # e.g. \"2025-01-03 to 2025-01-31\"\n",
    "# )\n",
    "#\n",
    "# # 之后你就可以用 feat_train 做训练，feat_valid 做 out-of-fold 验证（再算 AUC/F1）。\n",
    "# # Then you can use feat_train for training, and feat_valid for out-of-fold validation (e.g. compute AUC/F1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b97010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# =========================\n",
    "# Fast feature builder v3.0\n",
    "# =========================\n",
    "def build_feature_matrix_fast(\n",
    "    change_r4w: pd.DataFrame,\n",
    "    volume_r4w: pd.DataFrame,\n",
    "    cutoff: str | pd.Timestamp,\n",
    "    *,\n",
    "    # —— 主键与列名 / Keys & column names ——\n",
    "    id_col=\"Account ID\",\n",
    "    name_col_in_volume=\"account_name\",\n",
    "    order_col=\"rolling_order\",\n",
    "    firstb_col=\"first_b_stock_rw\",\n",
    "    # —— A/B 侧变化列 / change columns ——\n",
    "    a_change_cols=(\"change_4w_a_ms\", \"change_4w_a_stock\", \"change_a_freq\"),\n",
    "    b_change_cols=(\"change_4w_b_ms\", \"change_4w_b_stock\", \"change_b_freq\"),\n",
    "    # —— 窗口终点列（用于截止过滤）/ window-end column for cutoff ——\n",
    "    end_range_col=\"rolling_window_range_end\",\n",
    "    # —— before 段回看窗口长度 / lookback window length (before-B only) ——\n",
    "    before_lookback_orders=52,\n",
    "    # （可选）after 段限制长度；None=不限制\n",
    "    post_weeks: int | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    构建特征矩阵（含 before_B & after_B），且：\n",
    "      - 仅使用窗口终点 <= cutoff 的行\n",
    "      - before 段只统计 “first_B 之前最近 `before_lookback_orders` 个窗口”\n",
    "      - 输出中强制包含 account_name（来自 volume_r4w）\n",
    "\n",
    "    Build feature matrix with before/after-B splits, using windows with end <= cutoff.\n",
    "    'before' phase only counts the last `before_lookback_orders` windows prior to first-B.\n",
    "    Always returns `account_name` (merged from volume_r4w).\n",
    "    \"\"\"\n",
    "\n",
    "    df = change_r4w.copy()\n",
    "\n",
    "    # ---------- 0) 截止日期过滤（从 range 字符串解析 end 日期） ----------\n",
    "    # Parse window end date from e.g. \"2025-01-03 to 2025-01-31\" -> take the first date\n",
    "    if end_range_col not in df.columns:\n",
    "        raise ValueError(\n",
    "            f\"Column '{end_range_col}' not found in change_r4w; \"\n",
    "            f\"please provide a window-end column for cutoff filtering.\"\n",
    "        )\n",
    "    end_dates = pd.to_datetime(\n",
    "        df[end_range_col].astype(str).str.split(\" to \").str[0],\n",
    "        errors=\"coerce\"\n",
    "    )\n",
    "    cutoff = pd.to_datetime(cutoff)\n",
    "    df = df.loc[end_dates.le(cutoff)].copy()\n",
    "\n",
    "    # ---------- 1) 基本列检查 / sanity checks ----------\n",
    "    need_cols = [id_col, order_col, firstb_col, *a_change_cols, *b_change_cols]\n",
    "    missing = [c for c in need_cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns in change_r4w: {missing}\")\n",
    "\n",
    "    # ---------- 2) 相位标记（before / after） ----------\n",
    "    df = df.sort_values([id_col, order_col]).copy()\n",
    "    df[\"__before\"] = df[order_col] < df[firstb_col]\n",
    "    df[\"__after\"]  = df[order_col] >= df[firstb_col]\n",
    "\n",
    "    # ---------- 3) 截断 before 段为“first_B 之前最近 52 个窗口” ----------\n",
    "    # Limit 'before' phase to last `before_lookback_orders` windows prior to first-B\n",
    "    bounds = (\n",
    "        df[[id_col, firstb_col]]\n",
    "        .drop_duplicates(subset=[id_col])\n",
    "        .assign(__lb=lambda x: (x[firstb_col] - before_lookback_orders).clip(lower=1))\n",
    "        .rename(columns={firstb_col: \"__fb\"})\n",
    "    )\n",
    "    df = df.merge(bounds[[id_col, \"__lb\", \"__fb\"]], on=id_col, how=\"left\")\n",
    "    mask_before_window = (df[order_col] >= df[\"__lb\"]) & (df[order_col] < df[\"__fb\"])\n",
    "    df[\"__before\"] = df[\"__before\"] & mask_before_window\n",
    "\n",
    "    # （可选）after 段限制长度（例如仅保留首购后 52 周）\n",
    "    if post_weeks is not None:\n",
    "        df[\"__after\"] = df[\"__after\"] & (df[order_col] < (df[\"__fb\"] + post_weeks))\n",
    "\n",
    "    # ---------- 4) A 面：before/after 的 neg/pos/zero + volatility ----------\n",
    "    out_parts = []\n",
    "    g = df.groupby(id_col, group_keys=True)\n",
    "\n",
    "    def _phase_counts_and_vol(col: str, phase_col: str, phase_name: str) -> pd.DataFrame:\n",
    "        # 用掩码保留该相位的数据，其余置 NaN；groupby.std 会自动忽略 NaN\n",
    "        vals = df[col].to_numpy()\n",
    "        m = df[phase_col].to_numpy()\n",
    "        phase_vals = np.where(m, vals, np.nan)\n",
    "\n",
    "        tmp = df[[id_col]].copy()\n",
    "        tmp[f\"__{col}_phase\"] = phase_vals\n",
    "\n",
    "        neg_ct = g.apply(lambda x: ((x[col] < 0) & x[phase_col]).sum()).rename(f\"{col}_neg_{phase_name}\")\n",
    "        pos_ct = g.apply(lambda x: ((x[col] > 0) & x[phase_col]).sum()).rename(f\"{col}_pos_{phase_name}\")\n",
    "        zer_ct = g.apply(lambda x: ((x[col] == 0) & x[phase_col]).sum()).rename(f\"{col}_no_change_{phase_name}\")\n",
    "        vol    = tmp.groupby(id_col, as_index=True)[f\"__{col}_phase\"].std(ddof=1).rename(f\"{col}_volatility_{phase_name}\")\n",
    "\n",
    "        return pd.concat([neg_ct, pos_ct, zer_ct, vol], axis=1)\n",
    "\n",
    "    for col in a_change_cols:\n",
    "        out_parts.append(_phase_counts_and_vol(col, \"__before\", \"before\"))\n",
    "        out_parts.append(_phase_counts_and_vol(col, \"__after\",  \"after\"))\n",
    "\n",
    "    df_change_features = pd.concat(out_parts, axis=1)\n",
    "    df_change_features.index.name = id_col\n",
    "    df_change_features = df_change_features.reset_index()\n",
    "\n",
    "    # ---------- 5) first_drop / first_rise（基于“<=cutoff”的全部窗口） ----------\n",
    "    fr_parts = []\n",
    "    for col in (*a_change_cols, *b_change_cols):\n",
    "        mask_drop = df[col] < 0\n",
    "        mask_rise = df[col] > 0\n",
    "        first_drop = df.loc[mask_drop].groupby(id_col)[order_col].min().rename(f\"{col}_first_drop_order\")\n",
    "        first_rise = df.loc[mask_rise].groupby(id_col)[order_col].min().rename(f\"{col}_first_rise_order\")\n",
    "        fr_parts.append(first_drop)\n",
    "        fr_parts.append(first_rise)\n",
    "    df_firsts = pd.concat(fr_parts, axis=1).reset_index()\n",
    "\n",
    "    # ---------- 6) B 面汇总（不分相位）：pos_count & volatility ----------\n",
    "    b_parts = []\n",
    "    for col in b_change_cols:\n",
    "        pos_count = df.groupby(id_col)[col].apply(lambda s: (s > 0).sum()).rename(f\"{col}_pos_count\")\n",
    "        vol = df.groupby(id_col)[col].std(ddof=1).rename(f\"{col}_volatility\")\n",
    "        b_parts.append(pos_count)\n",
    "        b_parts.append(vol)\n",
    "    df_b_summary = pd.concat(b_parts, axis=1).reset_index()\n",
    "\n",
    "    # ---------- 7) 连续串（before: a_stock；after: a_ms） ----------\n",
    "    def _count_consecutive_neg(x: pd.Series, k: int) -> int:\n",
    "        arr = x.to_numpy()\n",
    "        n, streak = 0, 0\n",
    "        for v in arr:\n",
    "            if pd.notna(v) and (v < 0):\n",
    "                streak += 1\n",
    "                if streak == k:\n",
    "                    n += 1\n",
    "                    streak -= 1  # 允许重叠 / allow overlapping\n",
    "            else:\n",
    "                streak = 0\n",
    "        return n\n",
    "\n",
    "    def _streak_block(group: pd.DataFrame) -> pd.Series:\n",
    "        out = {}\n",
    "        g_before = group.loc[group[\"__before\"]]\n",
    "        g_after  = group.loc[group[\"__after\"]]\n",
    "        for K in (3, 4, 5):\n",
    "            out[f\"a_stocking_{K}fall_before_b\"] = _count_consecutive_neg(g_before[\"change_4w_a_stock\"], K)\n",
    "        for K in (3, 4, 5):\n",
    "            out[f\"a_ms_{K}fall_after_b\"] = _count_consecutive_neg(g_after[\"change_4w_a_ms\"], K)\n",
    "        return pd.Series(out)\n",
    "\n",
    "    df_streaks = df.groupby(id_col, as_index=False).apply(_streak_block).reset_index(drop=True)\n",
    "\n",
    "    # ---------- 8) 合并所有特征 ----------\n",
    "    features = (\n",
    "        df_change_features\n",
    "        .merge(df_firsts,    on=id_col, how=\"left\")\n",
    "        .merge(df_b_summary, on=id_col, how=\"left\")\n",
    "        .merge(df_streaks,   on=id_col, how=\"left\")\n",
    "    )\n",
    "\n",
    "    # ---------- 9) 追加账户名，并将其置于第2列 ----------\n",
    "    # Merge `account_name` from volume_r4w and move it right after id_col\n",
    "    if name_col_in_volume in volume_r4w.columns:\n",
    "        # 尝试识别 volume_r4w 的 ID 列名\n",
    "        id_candidates = [c for c in volume_r4w.columns if c.lower() in (\"account id\", \"account_id\", \"id\")]\n",
    "        if id_candidates:\n",
    "            id_in_volume = id_candidates[0]\n",
    "            names = volume_r4w[[id_in_volume, name_col_in_volume]].drop_duplicates()\n",
    "            names = names.rename(columns={id_in_volume: id_col})\n",
    "            features = features.merge(names, on=id_col, how=\"left\")\n",
    "\n",
    "    # 将列顺序调整为：id, account_name, 其它特征\n",
    "    cols = features.columns.tolist()\n",
    "    front = [id_col]\n",
    "    if name_col_in_volume in cols:\n",
    "        front.append(name_col_in_volume)\n",
    "    rest = [c for c in cols if c not in front]\n",
    "    features = features[front + rest]\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "# =============================\n",
    "# 便捷函数：一键生成 Train/Valid\n",
    "# =============================\n",
    "def build_train_valid_features(\n",
    "    change_r4w: pd.DataFrame,\n",
    "    volume_r4w: pd.DataFrame,\n",
    "    *,\n",
    "    cutoff_train=\"2025-08-29\",\n",
    "    cutoff_valid=\"2025-10-03\",\n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    生成两套特征矩阵：\n",
    "      - Train: 仅使用 <= cutoff_train 的窗口\n",
    "      - Valid: 仅使用 <= cutoff_valid 的窗口（更靠近当前，天然 out-of-fold）\n",
    "    \"\"\"\n",
    "    feat_train = build_feature_matrix_fast(change_r4w, volume_r4w, cutoff_train, **kwargs)\n",
    "    feat_valid = build_feature_matrix_fast(change_r4w, volume_r4w, cutoff_valid, **kwargs)\n",
    "    return feat_train, feat_valid\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
